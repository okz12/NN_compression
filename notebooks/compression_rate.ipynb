{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0,'../src/')\n",
    "\n",
    "with open(\"prune_model_dict.p\", \"rb\") as handle:\n",
    "    prune_dict = pickle.load(handle)\n",
    "#with open(\"prune_gmp.p\", \"rb\") as handle:\n",
    "#    prune_gmp = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compressed_model():\n",
    "    def __init__(self, state_dict, gmp_list):\n",
    "        #could be multiple gmps\n",
    "        #could be multiple gmp scales\n",
    "        gmp_means = []\n",
    "        self.scale_len = 0\n",
    "        for g in gmp_list:\n",
    "            gmp_means.append(list(g.means.clone().data.cpu().numpy()))\n",
    "            \n",
    "        if (g.scaling):#if scaling , only one gmp should be present\n",
    "            weights = torch.cat([state_dict[layer].view(-1) * g.scale.data.exp()[int(i/2)] for i,layer in enumerate(state_dict)]).cpu().numpy()\n",
    "            self.scale_len = float(g.scale.size()[0])\n",
    "        else:\n",
    "            weights = torch.cat([state_dict[layer].view(-1) for layer in state_dict]).cpu().numpy()\n",
    "            \n",
    "        means = np.sort( np.append( np.array(gmp_means), np.zeros(1)) )\n",
    "        bins = means + 0.001 * abs(means)\n",
    "        binned_weights = np.digitize(pd, bins, right=True)\n",
    "\n",
    "        unique, counts = np.unique(binned_weights, return_counts=True)\n",
    "        zero_idx = np.argmax(counts)\n",
    "        binned_weights[ binned_weights==unique[zero_idx] ] = 0\n",
    "        new_means = []\n",
    "        new_means.append(0.0)\n",
    "\n",
    "        set_idx = 1\n",
    "        for idx in unique:\n",
    "            if idx != unique[zero_idx]:\n",
    "                new_means.append(means[idx])\n",
    "                binned_weights[ binned_weights==idx] = set_idx\n",
    "                set_idx += 1\n",
    "                \n",
    "        self.binned_weights = binned_weights\n",
    "        self.means = means\n",
    "\n",
    "    def encode(self, index_bits):\n",
    "        index_spacing = index_bits**2\n",
    "        index_list = []\n",
    "        weight_list = []\n",
    "        index_counter=0\n",
    "        for pos, weight in enumerate(list(self.binned_weights)):\n",
    "            index_counter+=1\n",
    "            if (weight==0):\n",
    "                if index_counter==index_spacing:\n",
    "                    index_list.append(index_spacing)\n",
    "                    weight_list.append(0)\n",
    "                    index_counter=0\n",
    "            else:\n",
    "                weight_list.append(weight)\n",
    "                index_list.append(index_counter)\n",
    "                index_counter=0\n",
    "        if(index_counter>0):\n",
    "            index_list.append(index_counter)\n",
    "            weight_list.append(0)\n",
    "        return index_list, weight_list\n",
    "    \n",
    "    def decode(self, index_list, weight_list):\n",
    "        R_recov = []\n",
    "        for index, weight in zip(index_list, weight_list):\n",
    "            for z in range(int(index-1)):\n",
    "                R_recov.append(0)\n",
    "            R_recov.append(weight)\n",
    "        return R_recov\n",
    "    \n",
    "    def recover(self):\n",
    "        unique, counts = np.unique(self.binned_weights, return_counts=True)\n",
    "        pd_recov = np.zeros(self.binned_weights.size)\n",
    "\n",
    "        for u, nm in zip(unique, self.means):\n",
    "            pd_recov[ binned_weights==u ] = nm\n",
    "            print(u, nm)\n",
    "            print(pd_recov)\n",
    "        return pd_recov\n",
    "    \n",
    "    def get_cr(self, index_bits=0):\n",
    "        full_size = self.binned_weights.size * 32\n",
    "        codebook_size = 32 * (np.ceil(np.log2(self.means.size)) + np.ceil(np.log2(self.scale_len)))\n",
    "        min_idx_bit = 0\n",
    "        min_idx_size = -1\n",
    "        if (index_bits !=0):\n",
    "            index_list, weight_list = self.encode(index_bits)\n",
    "            index_size = len(index_list) * index_bits\n",
    "            weight_size = len(weight_list) * np.ceil(np.log2(self.means.size))\n",
    "            return ((full_size / (codebook_size + weight_size + index_size)), min_idx_bit)\n",
    "        \n",
    "        for index_bits in range (6,11):\n",
    "            index_list, weight_list = self.encode(index_bits)\n",
    "            index_size = len(index_list) * index_bits\n",
    "            weight_size = len(weight_list) * np.ceil(np.log2(self.means.size))\n",
    "            if (index_size + weight_size < min_idx_size or min_idx_size ==-1):\n",
    "                min_idx_size = index_size + weight_size\n",
    "                min_idx_bit = index_bits\n",
    "        return ((full_size / (codebook_size + min_idx_size)), min_idx_bit)\n",
    "        \n",
    "        \n",
    "    \n",
    "a = compressed_model(prune_dict, [prune_gmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_cr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.means.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "csc_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc_mat = csc_matrix(prune_dict['fc1.weight'])\n",
    "A = csc_mat.data\n",
    "IR = csc_mat.indices\n",
    "IC = csc_mat.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1250])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_dict['fc1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10204,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10204,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csc_mat.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csc_mat.indptr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to unscaled means\n",
    "pd = torch.cat([prune_dict[layer].view(-1) * prune_gmp.scale.data.exp()[int(i/2)] for i,layer in enumerate(prune_dict)]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  8  9 ...  8 11  8]\n",
      "{1: 2303, 3: 3448, 5: 3701, 7: 15, 8: 628409, 9: 660, 11: 2626, 13: 1050, 14: 241, 15: 7}\n",
      "[ 1  3  5  7  8  9 11 13 14 15]\n",
      "[  2303   3448   3701     15 628409    660   2626   1050    241      7]\n",
      "[ 7  0  9 ...  0 11  0]\n"
     ]
    }
   ],
   "source": [
    "means = np.sort( np.append(prune_gmp.means.data.clone().cpu().numpy(), np.zeros(1)) )\n",
    "bins = means + 0.001 * abs(means)\n",
    "binned_weights = np.digitize(pd, bins, right=True)\n",
    "print (binned_weights)\n",
    "\n",
    "unique, counts = np.unique(binned_weights, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print (unique)\n",
    "print (counts)\n",
    "zero_idx = np.argmax(counts)\n",
    "binned_weights[ binned_weights==unique[zero_idx] ] = 0\n",
    "print (binned_weights)\n",
    "new_means = []\n",
    "new_means.append(0.0)\n",
    "\n",
    "set_idx = 1\n",
    "for idx in unique:\n",
    "    if idx != unique[zero_idx]:\n",
    "        new_means.append(means[idx])\n",
    "        binned_weights[ binned_weights==idx] = set_idx\n",
    "        set_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1 -0.5548520684242249\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "2 -0.275088906288147\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "3 -0.16535350680351257\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "4 -0.04979413375258446\n",
      "[-0.04979413  0.          0.         ...  0.          0.\n",
      "  0.        ]\n",
      "5 0.08361522108316422\n",
      "[-0.04979413  0.          0.08361522 ...  0.          0.\n",
      "  0.        ]\n",
      "6 0.19607827067375183\n",
      "[-0.04979413  0.          0.08361522 ...  0.          0.19607827\n",
      "  0.        ]\n",
      "7 0.3386446237564087\n",
      "[-0.04979413  0.          0.08361522 ...  0.          0.19607827\n",
      "  0.        ]\n",
      "8 0.5209544897079468\n",
      "[-0.04979413  0.          0.08361522 ...  0.          0.19607827\n",
      "  0.        ]\n",
      "9 0.7065592408180237\n",
      "[-0.04979413  0.          0.08361522 ...  0.          0.19607827\n",
      "  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.04979413,  0.        ,  0.08361522, ...,  0.        ,\n",
       "        0.19607827,  0.        ])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(binned_weights, return_counts=True)\n",
    "pd_recov = np.zeros(binned_weights.size)\n",
    "\n",
    "for u, nm in zip(unique, new_means):\n",
    "    pd_recov[ binned_weights==u ] = nm\n",
    "    print(u, nm)\n",
    "    print(pd_recov)\n",
    "pd_recov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd - pd_recov).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[x,list(pd).count(x)] for x in set(list(pd))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf50c276b2b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnl2k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m200000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m200000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnl2k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#naive calculation\n",
    "nb = 200000 * 32\n",
    "kb = 16 * 32\n",
    "nl2k = 0.005 * 200000 * np.log2(16) + 200000/16 * np.log2(16)\n",
    "(nb/(kb + nl2k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.443457621222713"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_elements = 266610\n",
    "pruning_rate = 0.043/2\n",
    "index_bits = 5\n",
    "#number_of_elements = 400000\n",
    "#pruning_rate = 0.005/2\n",
    "#index_bits = 6\n",
    "\n",
    "orig = number_of_elements * 32 #266k elements at 32 bit precision\n",
    "codebook = 16 * 32 # 16 cluster means at 32 bit preicison\n",
    "weight = number_of_elements * np.log2(32) * (pruning_rate + 1/(2**index_bits))\n",
    "index = number_of_elements * index_bits * (pruning_rate + 1/(2**index_bits))\n",
    "(orig/(codebook + weight + index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-a266ec639496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd_recov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mindex_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindex_bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mweight_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mcodebook_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index_list' is not defined"
     ]
    }
   ],
   "source": [
    "#encode\n",
    "R = np.random.rand(400000)\n",
    "R[R<=0.995] = 0\n",
    "R[R>0.995] = 1/100\n",
    "'''\n",
    "R[R>0.990] = 2/100\n",
    "R[R>0.985] = 3/100\n",
    "R[R>0.980] = 4/100\n",
    "R[R>0.975] = 5/100\n",
    "R[R>0.970] = 6/100\n",
    "R[R>0.965] = 7/100\n",
    "R[R>0.960] = 8/100\n",
    "R[R>0.959] = 9/100\n",
    "R[R>0.957] = 10/100\n",
    "'''\n",
    "\n",
    "R=R*100\n",
    "#[[x,list(R).count(x)] for x in set(list(R))]\n",
    "\n",
    "#code_list\n",
    "\n",
    "\n",
    "print(full_size, len(weight_list), index_size, weight_size, codebook_size, full_size/(index_size + weight_size + codebook_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(R - R_recov).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
