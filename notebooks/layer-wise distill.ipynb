{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "#Expand notebook to take full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "#Jupyter magic to notify when a cell finishes execution with %%notify command -- does not work with Jupyterlab\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "###\n",
    "import sys\n",
    "sys.path.insert(0,'../src/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.nn.modules import Module\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "model_dir = \"./models/\"\n",
    "import model_archs\n",
    "from utils_plot import show_sws_weights, show_weights, print_dims, prune_plot, draw_sws_graphs, joint_plot\n",
    "from utils_model import test_accuracy, train_epoch, retrain_sws_epoch, model_prune, get_weight_penalty, layer_accuracy\n",
    "from utils_misc import trueAfterN, logsumexp, root_dir, model_load_dir\n",
    "from utils_sws import GaussianMixturePrior, special_flatten, KL, compute_responsibilies, merger, sws_prune, sws_prune_l2\n",
    "from mnist_loader import search_train_data, search_retrain_data, search_validation_data, train_data, test_data, batch_size\n",
    "from extract_targets import get_targets\n",
    "retraining_epochs = 50\n",
    "\n",
    "def retrain_layer(model_retrain, model_orig, data_loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, temp, loss_type = 'MSEL', data_size = 'search', savedir = ''):\n",
    "    \n",
    "    weight_loader = model_retrain.state_dict()\n",
    "    for layer in model_retrain.state_dict():\n",
    "        weight_loader[layer] = model_orig.state_dict()[layer]\n",
    "    model_retrain.load_state_dict(weight_loader)\n",
    "\n",
    "    exp_name = \"{}_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(model_retrain.name, alpha, beta, retraining_epochs, tau, int(mixtures), int(temp), data_size)\n",
    "    gmp = GaussianMixturePrior(mixtures, [x for x in model_retrain.parameters()], 0.99, ab = (alpha, beta), scaling = False)\n",
    "    gmp.print_batch = False\n",
    "\n",
    "    print (\"Model Name: {}\".format(model_retrain.name))\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = torch.optim.Adam([\n",
    "        {'params': model_retrain.parameters(), 'lr': 1e-4},\n",
    "        {'params': [gmp.means], 'lr': 1e-4},\n",
    "        {'params': [gmp.gammas, gmp.rhos], 'lr': 3e-3}])#log precisions and mixing proportions\n",
    "\n",
    "    \n",
    "    for epoch in range(retraining_epochs):\n",
    "        model_retrain, loss = retrain_sws_epoch(model_retrain, gmp, opt, criterion, data_loader, tau, temp, loss_type)\n",
    "\n",
    "        if (trueAfterN(epoch, 10)):\n",
    "            print('Epoch: {}. Loss: {:.2f}'.format(epoch+1, float(loss.data)))\n",
    "            layer_accuracy(model_retrain, gmp, model_orig, test_data_full, test_labels_full)\n",
    "            \n",
    "    if(savedir!=\"\"):\n",
    "        torch.save(model_retrain, savedir + 'mnist_retrain_{}.m'.format(exp_name))\n",
    "        with open(savedir + 'mnist_retrain_{}_gmp.p'.format(exp_name),'wb') as f:\n",
    "            pickle.dump(gmp, f)\n",
    "            \n",
    "    return model_retrain, gmp\n",
    "\n",
    "def get_layer_data(target_dir, temp, layer, model_name, data_size):\n",
    "    x_start = 0\n",
    "    x_end = 60000\n",
    "    if (data_size == \"search\"):\n",
    "        x_start = 40000\n",
    "        x_end = 50000\n",
    "    if (\"SWSModel\" in model_name):\n",
    "        if (layer == 1):\n",
    "            layer_model = model_archs.SWSModelConv1().cuda()\n",
    "            input = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "            output = get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end]\n",
    "        if (layer == 2):\n",
    "            layer_model = model_archs.SWSModelConv2().cuda()\n",
    "            input = nn.ReLU()(get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end])\n",
    "            output = (get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end])\n",
    "        if (layer == 3):\n",
    "            layer_model = model_archs.SWSModelFC1().cuda()\n",
    "            input = nn.ReLU()(get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end])\n",
    "            output = get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]\n",
    "        if (layer == 4):\n",
    "            layer_model = model_archs.SWSModelFC2().cuda()\n",
    "            input = nn.ReLU()(get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end])\n",
    "            output = get_targets(target_dir, temp, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end]\n",
    "\n",
    "    if (\"LeNet_300_100\" in model_name):\n",
    "        if (layer == 1):\n",
    "            layer_model = model_archs.LeNet_300_100FC1().cuda()\n",
    "            input = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "            output = get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]\n",
    "        if (layer == 2):\n",
    "            layer_model = model_archs.LeNet_300_100FC2().cuda()\n",
    "            input = nn.ReLU()(get_targets(target_dir, temp, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end])\n",
    "            output = (get_targets(target_dir, temp, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end])\n",
    "        if (layer == 3):\n",
    "            layer_model = model_archs.LeNet_300_100FC3().cuda()\n",
    "            input = nn.ReLU()(get_targets(target_dir, temp, [\"fc3.out\"])[\"fc3.out\"][x_start:x_end])\n",
    "            output = get_targets(target_dir, temp, [\"fc3.out\"])[\"fc3.out\"][x_start:x_end]\n",
    "\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(input.data, output.data)\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    return layer_model, loader\n",
    "\n",
    "def init_retrain_layer(alpha, beta, tau, temp, mixtures, model_name, data_size, layer, savedir = \"\"):\n",
    "    test_data_full =  Variable(test_data(fetch = \"data\")).cuda()\n",
    "    test_labels_full =  Variable(test_data(fetch = \"labels\")).cuda()\n",
    "    val_data_full =  Variable(search_validation_data(fetch = \"data\")).cuda()\n",
    "    val_labels_full =  Variable(search_validation_data(fetch = \"labels\")).cuda()\n",
    "\n",
    "    model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "    model_orig = torch.load(model_load_dir + model_file + '.m').cuda()\n",
    "\n",
    "    layer_model, loader = get_layer_data(target_dir, temp, layer, model_name, data_size)\n",
    "\n",
    "    model, gmp = retrain_layer(layer_model, model_orig, loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, temp, data_size, model_dir + model_file)\n",
    "    return model, gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44118ddb00>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f447c31fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_init_means(start, end, jump):\n",
    "    numlist = (list(range(-end, -start + 1, jump)) + list(range(start, end + 1, jump)))\n",
    "    return [x/100.0 for x in numlist]\n",
    "    \n",
    "mean_mult = np.array(list(range(retraining_epochs))) - (retraining_epochs-1)/2\n",
    "mean_mult = 5 * mean_mult/mean_mult.max()\n",
    "mean_mult = (0.1 + 0.9 * (1.0/(1.0 + np.exp(mean_mult)))) * 1e-10\n",
    "plt.plot(mean_mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mean = 20000\n",
    "var = 2\n",
    "zmean = 20000\n",
    "zvar = 10\n",
    "#means = get_init_means(8, 60, 9)\n",
    "#print (means)\n",
    "mixtures = 15\n",
    "temp = 5\n",
    "tau = 1e-8\n",
    "def layer_exp(mean, var, zmean, zvar, mixtures, temp, tau, layer = 1, loss_type):\n",
    "    data_size = 'search'\n",
    "    model_name = 'LeNet_300_100'\n",
    "\n",
    "    beta = mean/var\n",
    "    alpha = mean * beta\n",
    "    ab = (alpha, beta)\n",
    "    zbeta = zmean/zvar\n",
    "    zalpha = zmean * zbeta\n",
    "    zab = (zalpha, beta)\n",
    "    \n",
    "    #tau_scd = np.array(list(range(retraining_epochs))) - (retraining_epochs-1)/2\n",
    "    #tau_scd = 5 * tau_scd/tau_scd.max()\n",
    "    #tau_scd = (0.1 + 0.9 * (1.0/(1.0 + np.exp(tau_scd)))) * 1e-10\n",
    "\n",
    "    model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "    full_model = torch.load(model_load_dir + model_file + \".m\")\n",
    "\n",
    "    (x_start, x_end) = (25000, 50000)\n",
    "    if(layer == 1):\n",
    "        layer_model = model_archs.LeNet_300_100FC1().cuda()\n",
    "        input = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "        output = (get_targets(model_file, 0, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]).cuda()\n",
    "    if(layer == 2):\n",
    "        layer_model = model_archs.LeNet_300_100FC2().cuda()\n",
    "        input = (get_targets(model_file, 0, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]).cuda()\n",
    "        input = nn.ReLU()(input)\n",
    "        input = input/temp\n",
    "        output = (get_targets(model_file, 0, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end]).cuda()\n",
    "    #output = (get_targets(model_file, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]).cuda()\n",
    "    \n",
    "    ###ReLU Check\n",
    "    output = nn.ReLU()(output)\n",
    "    output = nn.Softmax(dim=1)(output/temp)\n",
    "\n",
    "    test_data_full = Variable(test_data(fetch = \"data\")).cuda()\n",
    "    test_labels_full = Variable(test_data(fetch = \"labels\")).cuda()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(input.data, output.data)\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    state_dict = copy.deepcopy(layer_model.state_dict())\n",
    "    for layer in state_dict:\n",
    "        state_dict[layer] = full_model.state_dict()[layer]\n",
    "    layer_model.load_state_dict(state_dict)\n",
    "\n",
    "    exp_name = \"{}_a{}_za{}_r{}_t{}_m{}_kdT{}_{}\".format(layer_model.name, ab[0], zab[0], retraining_epochs, tau, int(mixtures), int(temp), data_size)\n",
    "    gmp = GaussianMixturePrior(mixtures, [x for x in layer_model.parameters()], 0.999, zero_ab = (zalpha, zbeta), ab = (alpha, beta), scaling = False)\n",
    "    gmp.print_batch = False\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = torch.optim.Adam([\n",
    "        {'params': layer_model.parameters(), 'lr': 5e-4},\n",
    "        {'params': [gmp.means], 'lr': 3e-4},\n",
    "        {'params': [gmp.gammas, gmp.rhos], 'lr': 3e-3}])#log precisions and mixing proportions\n",
    "\n",
    "    for epoch in range(50):\n",
    "        #mean = mean_mult[epoch]\n",
    "        #mean = 50000\n",
    "        #beta = mean/var\n",
    "        #alpha = mean * beta\n",
    "        #gmp.ab = (alpha, beta)\n",
    "\n",
    "        layer_model, loss = retrain_sws_epoch(layer_model, gmp, opt, criterion, loader, tau, temp, loss_type)\n",
    "\n",
    "        if (trueAfterN(epoch, 10)):\n",
    "            print('Epoch: {}. Loss: {:.2f}'.format(epoch+1, float(loss.data)))\n",
    "            show_sws_weights(model = layer_model, means = list(gmp.means.data.clone().cpu()), precisions = list(gmp.gammas.data.clone().cpu()))\n",
    "            res = layer_accuracy(layer_model, gmp, full_model, test_data_full, test_labels_full)\n",
    "    \n",
    "    res = layer_accuracy(layer_model, gmp, full_model, test_data_full, test_labels_full)\n",
    "    return layer_model, gmp, \"{:.2f}|{:.2f}_{:.2f}|{:.2f}\".format(res[0], res[1], res[2], res[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-component Mean: 50000.0 Variance: 10.0\n",
      "Non-zero component Mean: 50000.0 Variance: 2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d371ae32ea36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-977dd278f4d1>\u001b[0m in \u001b[0;36mlayer_exp\u001b[0;34m(mean, var, zmean, zvar, mixtures, temp, tau, layer)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#gmp.ab = (alpha, beta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain_sws_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrueAfterN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NNC/NN_compression/src/utils_model.py\u001b[0m in \u001b[0;36mretrain_sws_epoch\u001b[0;34m(model, gmp, optimizer, criterion, train_loader, tau, temp, loss_type)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m#MSE Hidden Activation - no temp - ReLU - MSE Loss - no mult by temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m#MSE Logit / Hidden No Act - no temp - MSE Loss - no mult by temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_acc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;31m# Updating parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NNC/NN_compression/src/utils_sws.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, mask)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"0-neglogprop Loss: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneglogprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneglogprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# ... and all other component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/okz21/NNC/NN_compression/src/utils_sws.py\u001b[0m(98)\u001b[0;36mcall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     96 \u001b[0;31m        \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m            \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"0-neglogprop Loss: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneglogprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 98 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneglogprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     99 \u001b[0;31m        \u001b[0;31m# ... and all other component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "layer_model, gmp, res = layer_exp(50000, 2, 50000, 10, 15, 4, 1e-9, 1, 'MSEHA')\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 98.26% - Retrain: 97.24% - Prune: 95.52% - Quantize: 94.95% - Sparsity: 97.40%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97.24, 95.52, 94.95, 97.40382165605097)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "full_model = torch.load(model_load_dir + model_file + \".m\")\n",
    "layer_accuracy(layer_model, gmp, full_model, test_data_full, test_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 'search'\n",
    "model_name = 'LeNet_300_100'\n",
    "model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "\n",
    "test_data_full = Variable(test_data(fetch = \"data\")).cuda()\n",
    "test_labels_full = Variable(test_data(fetch = \"labels\")).cuda()\n",
    "\n",
    "(x_start, x_end) = (40000, 50000)\n",
    "images = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "targets = (get_targets(model_file, 0, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]).cuda()\n",
    "targets = nn.ReLU()(targets)\n",
    "targets = nn.Softmax(dim=1)(targets/temp)\n",
    "\n",
    "forward = layer_model(test_data_full)\n",
    "outputs = nn.LogSoftmax(dim=1)((nn.ReLU()(forward))/temp)\n",
    "loss_soft_target = -torch.mean(torch.sum(targets * outputs, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-component Mean: 20000.0 Variance: 10000.0\n",
      "Non-zero component Mean: 50000.0 Variance: 2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fb3398726ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6cbb7ba4a3cf>\u001b[0m in \u001b[0;36mlayer_exp\u001b[0;34m(mean, var, zmean, zvar, mixtures, temp, tau)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#gmp.ab = (alpha, beta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain_sws_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrueAfterN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NNC/NN_compression/src/utils_model.py\u001b[0m in \u001b[0;36mretrain_sws_epoch\u001b[0;34m(model, gmp, optimizer, criterion, train_loader, tau, temp)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;31m#MSE Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;31m# Calculate Loss: softmax --> cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NNC/NN_compression/src/utils_sws.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mweight_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixing_proportions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mweight_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixing_proportions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Layer Loss: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NNC/NN_compression/src/utils_sws.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, weights, mixing_proportions, means, precision)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixing_proportions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0munnormalized_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m#unnormalized_log_likelihood = (-1/2) * precision.matmul((diff ** 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"f1286795-0ce6-47a1-b058-525779b5e05b\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"f1286795-0ce6-47a1-b058-525779b5e05b\") === null) {\n",
       "                var notificationPayload = {\"body\": \"Cell execution has finished!\", \"icon\": \"/static/base/images/favicon.ico\", \"requireInteraction\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "res_str = []\n",
    "res_str.append(layer_exp(50000, 2, 20000, 10000, 15, 4, 1e-8))\n",
    "res_str.append(layer_exp(20000, 2, 80000, 10, 15, 5, 1e-8))\n",
    "fin = \"\\n\".join(res_str)\n",
    "fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
