{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Expand notebook to take full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob, os\n",
    "os.chdir(\"./models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for file in glob.glob(\"*mnist*\"):\n",
    "    file_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in file_list:\n",
    "    temp_str = filename.split(\"_\")[7]\n",
    "    mix_str = filename.split(\"_\")[8]\n",
    "    #print (filename, temp_str, mix_str)\n",
    "    if 'm' in temp_str:\n",
    "        temp = \"kdT\" + str(int(float(temp_str.split(\"m\")[1])))\n",
    "        mix = \"m\" + mix_str.split(\"kdT\")[1]\n",
    "        new_filename = filename.replace(mix_str, temp).replace(temp_str, mix)\n",
    "        subprocess.call(\"mv {} {}\".format(filename, new_filename).split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing temp from sobol sequence and deduping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open(\"../sobol_search.p\", \"rb\") as handle:\n",
    "    params = pickle.load(handle)\n",
    "\n",
    "tupled_params = [tuple(row) for row in np.vstack((params['mean'], params['var'], params['tau'], params['mixtures'])).T]\n",
    "unique_params = list(set(tupled_params))\n",
    "\n",
    "reduced_params = {}\n",
    "reduced_params['mean'] = np.array([x[0] for x in unique_params])\n",
    "reduced_params['var'] = np.array([x[1] for x in unique_params])\n",
    "reduced_params['tau'] = np.array([x[2] for x in unique_params])\n",
    "reduced_params['mixtures'] = np.array([int(x[3]) for x in unique_params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../src/')\n",
    "import os\n",
    "import argparse\n",
    "from retrain_model import retrain_model\n",
    "savedir = os.getcwd() + \"/models/\"\n",
    "\n",
    "import pickle\n",
    "from mnist_loader import train_data\n",
    "from utils_sws import sws_prune, compressed_model\n",
    "from utils_model import test_accuracy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mnist_loader import search_train_data, search_retrain_data, search_validation_data, train_data, test_data, batch_size\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.05725487884358381, var: 0.3043676123956402, tau: 3.9153756672351225e-06, temp: 14.0, mixtures: 6\n",
      "./models/mnist_retrain_SWSModel_a0.010770269298995945_b0.18811094384496982_r50_t3.9153756672351225e-06_m6_kdT14_search\n",
      "mean: 18105.58243027124, var: 0.3043676123956402, tau: 3.9153756672351225e-06, temp: 14.0, mixtures: 6\n",
      "./models/mnist_retrain_SWSModel_a1077026929.899596_b59485.903535413694_r50_t3.9153756672351225e-06_m6_kdT14_search\n",
      "mean: 0.05725487884358381, var: 0.16962590880724215, tau: 3.9153756672351225e-06, temp: 14.0, mixtures: 6\n",
      "./models/mnist_retrain_SWSModel_a0.01932559226620634_b0.33753616559040256_r50_t3.9153756672351225e-06_m6_kdT14_search\n",
      "mean: 0.05725487884358381, var: 0.3043676123956402, tau: 0.0003141017185010456, temp: 14.0, mixtures: 6\n",
      "./models/mnist_retrain_SWSModel_a0.010770269298995945_b0.18811094384496982_r50_t0.0003141017185010456_m6_kdT14_search\n",
      "mean: 0.05725487884358381, var: 0.3043676123956402, tau: 3.9153756672351225e-06, temp: 11.0, mixtures: 6\n",
      "./models/mnist_retrain_SWSModel_a0.010770269298995945_b0.18811094384496982_r50_t3.9153756672351225e-06_m6_kdT11_search\n",
      "mean: 0.05725487884358381, var: 0.3043676123956402, tau: 3.9153756672351225e-06, temp: 14.0, mixtures: 3\n",
      "./models/mnist_retrain_SWSModel_a0.010770269298995945_b0.18811094384496982_r50_t3.9153756672351225e-06_m3_kdT14_search\n",
      "mean: 0.05725487884358381, var: 0.16962590880724215, tau: 0.0003141017185010456, temp: 11.0, mixtures: 3\n",
      "./models/mnist_retrain_SWSModel_a0.01932559226620634_b0.33753616559040256_r50_t0.0003141017185010456_m3_kdT11_search\n",
      "mean: 18105.58243027124, var: 0.3043676123956402, tau: 0.0003141017185010456, temp: 11.0, mixtures: 3\n",
      "./models/mnist_retrain_SWSModel_a1077026929.899596_b59485.903535413694_r50_t0.0003141017185010456_m3_kdT11_search\n",
      "mean: 18105.58243027124, var: 0.16962590880724215, tau: 3.9153756672351225e-06, temp: 11.0, mixtures: 3\n",
      "./models/mnist_retrain_SWSModel_a1932559226.620637_b106738.30759454257_r50_t3.9153756672351225e-06_m3_kdT11_search\n",
      "mean: 18105.58243027124, var: 0.16962590880724215, tau: 0.0003141017185010456, temp: 14.0, mixtures: 3\n",
      "./models/mnist_retrain_SWSModel_a1932559226.620637_b106738.30759454257_r50_t0.0003141017185010456_m3_kdT14_search\n"
     ]
    }
   ],
   "source": [
    "test_data_full =  Variable(test_data(fetch = \"data\")).cuda()\n",
    "test_labels_full =  Variable(test_data(fetch = \"labels\")).cuda()\n",
    "val_data_full =  Variable(search_validation_data(fetch = \"data\")).cuda()\n",
    "val_labels_full =  Variable(search_validation_data(fetch = \"labels\")).cuda()\n",
    "start = 0\n",
    "end = 10\n",
    "\n",
    "with open(\"../sobol_search.p\", \"rb\") as handle:\n",
    "    params = pickle.load(handle)\n",
    "for i in range (start,end):\n",
    "    print (\"mean: {}, var: {}, tau: {}, temp: {}, mixtures: {}\".format(params['mean'][i], params['var'][i], params['tau'][i], float(params['temp'][i]), int(params['mixtures'][i])))\n",
    "    mean = float(params['mean'][i])\n",
    "    var = float(params['var'][i])\n",
    "    beta = mean/var\n",
    "    alpha = mean * beta\n",
    "\n",
    "    exp_name = \"{}_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format('SWSModel', alpha, beta, 50, float(params['tau'][i]), int(params['mixtures'][i]), int(params['temp'][i]), 'search')\n",
    "    model_file = \"./models/mnist_retrain_{}\".format(exp_name)\n",
    "    if not os.path.exists(\"{}.m\".format(model_file)):\n",
    "        print (\"File not found: {}.m\".format(model_file))\n",
    "    else:\n",
    "        model = torch.load(\"{}.m\".format(model_file)).cuda()\n",
    "        with open(\"{}_gmp.p\".format(model_file), \"rb\") as handle:\n",
    "            gmp = pickle.load(handle)\n",
    "        model.load_state_dict(sws_prune(model, gmp))\n",
    "        test_acc = test_accuracy(test_data_full, test_labels_full, model)[0]\n",
    "        val_acc = test_accuracy(val_data_full, val_labels_full, model)[0]\n",
    "        cm = compressed_model(model.state_dict(), [gmp])\n",
    "        cr = cm.get_cr(6)[0]\n",
    "        sp = (cm.binned_weights == 0).sum() / float(cm.binned_weights.size) * 100.0\n",
    "        if not os.path.exists(\"results.csv\"):\n",
    "            with open(\"results.csv\", \"w\") as out_csv:\n",
    "                out_csv.write(\"Exp, Mean, Var, Tau, Temp, Mixtures, Test Acc, Val Acc, Sparse, CR\\n\")\n",
    "                out_csv.write(\", \".join([str(x) for x in [i, params['mean'][i], params['var'][i], params['tau'][i], int(params['temp'][i]), int(params['mixtures'][i]), test_acc, val_acc, sp, cr]]) + \"\\n\")\n",
    "        else:\n",
    "            with open(\"results.csv\", \"a\") as out_csv:\n",
    "                out_csv.write(\", \".join([str(x) for x in [i, params['mean'][i], params['var'][i], params['tau'][i], int(params['temp'][i]), int(params['mixtures'][i]), test_acc, val_acc, sp, cr]]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
