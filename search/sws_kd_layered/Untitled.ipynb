{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Expand notebook to take full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layered Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execution example: python layer_retrain.py --layer 1 --alpha 2500 --beta 10 --tau 1e-6 --mixtures 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.nn.modules import Module\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "model_dir = \"./models/\"\n",
    "import model_archs\n",
    "from utils_plot import show_sws_weights, show_weights, print_dims, prune_plot, draw_sws_graphs, joint_plot\n",
    "from utils_model import test_accuracy, train_epoch, retrain_sws_epoch, model_prune, get_weight_penalty, layer_accuracy\n",
    "from utils_misc import trueAfterN, logsumexp\n",
    "from utils_sws import GaussianMixturePrior, special_flatten, KL, compute_responsibilies, merger, sws_prune\n",
    "from mnist_loader import search_train_data, search_retrain_data, search_validation_data, train_data, test_data, batch_size\n",
    "\n",
    "def retrain_layer(model_retrain, model_orig, data_loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir):\n",
    "    weight_loader = model_retrain.state_dict()\n",
    "    for layer in model_retrain.state_dict():\n",
    "        weight_loader[layer] = model_orig.state_dict()[layer]\n",
    "    model_retrain.load_state_dict(weight_loader)\n",
    "\n",
    "    exp_name = \"{}_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(model_retrain.name, alpha, beta, 50, tau, int(mixtures), int(temp), data_size)\n",
    "    gmp = GaussianMixturePrior(mixtures, [x for x in model_retrain.parameters()], 0.99, ab = (alpha, beta), scaling = False)\n",
    "    gmp.print_batch = False\n",
    "\n",
    "    print (\"Model Name: {}\".format(model_retrain.name))\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = torch.optim.Adam([\n",
    "        {'params': model_retrain.parameters(), 'lr': 1e-4},\n",
    "        {'params': [gmp.means], 'lr': 1e-4},\n",
    "        {'params': [gmp.gammas, gmp.rhos], 'lr': 3e-3}])#log precisions and mixing proportions\n",
    "\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        model_retrain, loss = retrain_sws_epoch(model_retrain, gmp, opt, criterion, data_loader, tau)\n",
    "\n",
    "        if (trueAfterN(epoch, 10)):\n",
    "            print('Epoch: {}. Loss: {:.2f}'.format(epoch+1, float(loss.data)))\n",
    "            layer_accuracy(model_retrain, gmp, model_orig, test_data_full, test_labels_full)\n",
    "            \n",
    "    if(model_save_dir!=\"\"):\n",
    "        torch.save(model_retrain, model_save_dir + '/mnist_retrain_{}.m'.format(exp_name))\n",
    "        with open(model_save_dir + '/mnist_retrain_{}_gmp.p'.format(exp_name),'wb') as f:\n",
    "            pickle.dump(gmp, f)\n",
    "            \n",
    "    return model_retrain, gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_misc import  model_load_dir\n",
    "from extract_targets import get_targets\n",
    "\n",
    "###\n",
    "alpha = 100\n",
    "beta = 10\n",
    "tau = 1e-6\n",
    "layer = 2\n",
    "mixtures = 6\n",
    "temp = 6\n",
    "\n",
    "data_size = 'search'\n",
    "\n",
    "###\n",
    "test_data_full =  Variable(test_data(fetch = \"data\")).cuda()\n",
    "test_labels_full =  Variable(test_data(fetch = \"labels\")).cuda()\n",
    "val_data_full =  Variable(search_validation_data(fetch = \"data\")).cuda()\n",
    "val_labels_full =  Variable(search_validation_data(fetch = \"labels\")).cuda()\n",
    "\n",
    "model_name = \"SWSModel\"\n",
    "model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "model_orig = torch.load(model_load_dir + model_file + '.m').cuda()\n",
    "target_dir = model_file.replace(\"search\", \"full\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 0\n",
    "x_end = 60000\n",
    "if (data_size == \"search\"):\n",
    "    x_start = 40000\n",
    "    x_end = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'> <class 'torch.autograd.variable.Variable'>\n"
     ]
    }
   ],
   "source": [
    "layer = 4\n",
    "if (layer == 1):\n",
    "    layer_model = model_archs.SWSModelConv1().cuda()\n",
    "    input = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "    output = get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end]\n",
    "if (layer == 2):\n",
    "    layer_model = model_archs.SWSModelConv2().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end]\n",
    "if (layer == 3):\n",
    "    layer_model = model_archs.SWSModelFC1().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]\n",
    "if (layer == 4):\n",
    "    layer_model = model_archs.SWSModelFC2().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end]\n",
    "\n",
    "print (type(input), type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-component Mean: 2500.0 Variance: 1250.0\n",
      "Non-zero component Mean: 10.0 Variance: 1.0\n",
      "Model Name: SWSModelConv2\n",
      "Epoch: 10. Loss: 11.15\n",
      "Original: 98.71% - Retrain: 98.58% - Prune: 13.15%\n",
      "Epoch: 20. Loss: 6.32\n",
      "Original: 98.71% - Retrain: 98.35% - Prune: 9.85%\n",
      "Epoch: 30. Loss: 3.75\n",
      "Original: 98.71% - Retrain: 98.16% - Prune: 9.74%\n",
      "Epoch: 40. Loss: 1.86\n",
      "Original: 98.71% - Retrain: 97.91% - Prune: 9.74%\n",
      "Epoch: 50. Loss: 1.07\n",
      "Original: 98.71% - Retrain: 97.72% - Prune: 9.74%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-02a08783c02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixtures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-61f70b96a632>\u001b[0m in \u001b[0;36mretrain_layer\u001b[0;34m(model_retrain, model_orig, data_loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlayer_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_retrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_retrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mnist_retrain_{}.m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mnist_retrain_{}_gmp.p'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = torch.utils.data.TensorDataset(input.data, output.data)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model, gmp = retrain_layer(layer_model, model_orig, loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir + model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
