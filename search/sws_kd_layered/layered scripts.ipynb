{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Expand notebook to take full screen width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layered Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execution example: python layer_retrain.py --layer 1 --alpha 2500 --beta 10 --tau 1e-6 --mixtures 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.nn.modules import Module\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "model_dir = \"./models/\"\n",
    "import model_archs\n",
    "from utils_plot import show_sws_weights, show_weights, print_dims, prune_plot, draw_sws_graphs, joint_plot\n",
    "from utils_model import test_accuracy, train_epoch, retrain_sws_epoch, model_prune, get_weight_penalty, layer_accuracy\n",
    "from utils_misc import trueAfterN, logsumexp\n",
    "from utils_sws import GaussianMixturePrior, special_flatten, KL, compute_responsibilies, merger, sws_prune\n",
    "from mnist_loader import search_train_data, search_retrain_data, search_validation_data, train_data, test_data, batch_size\n",
    "\n",
    "def retrain_layer(model_retrain, model_orig, data_loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir):\n",
    "    weight_loader = model_retrain.state_dict()\n",
    "    for layer in model_retrain.state_dict():\n",
    "        weight_loader[layer] = model_orig.state_dict()[layer]\n",
    "    model_retrain.load_state_dict(weight_loader)\n",
    "\n",
    "    exp_name = \"{}_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(model_retrain.name, alpha, beta, 50, tau, int(mixtures), int(temp), data_size)\n",
    "    gmp = GaussianMixturePrior(mixtures, [x for x in model_retrain.parameters()], 0.99, ab = (alpha, beta), scaling = False)\n",
    "    gmp.print_batch = False\n",
    "\n",
    "    print (\"Model Name: {}\".format(model_retrain.name))\n",
    "    criterion = nn.MSELoss()\n",
    "    opt = torch.optim.Adam([\n",
    "        {'params': model_retrain.parameters(), 'lr': 1e-4},\n",
    "        {'params': [gmp.means], 'lr': 1e-4},\n",
    "        {'params': [gmp.gammas, gmp.rhos], 'lr': 3e-3}])#log precisions and mixing proportions\n",
    "\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        model_retrain, loss = retrain_sws_epoch(model_retrain, gmp, opt, criterion, data_loader, tau)\n",
    "\n",
    "        if (trueAfterN(epoch, 10)):\n",
    "            print('Epoch: {}. Loss: {:.2f}'.format(epoch+1, float(loss.data)))\n",
    "            layer_accuracy(model_retrain, gmp, model_orig, test_data_full, test_labels_full)\n",
    "            \n",
    "    if(model_save_dir!=\"\"):\n",
    "        torch.save(model_retrain, model_save_dir + '/mnist_retrain_{}.m'.format(exp_name))\n",
    "        with open(model_save_dir + '/mnist_retrain_{}_gmp.p'.format(exp_name),'wb') as f:\n",
    "            pickle.dump(gmp, f)\n",
    "            \n",
    "    return model_retrain, gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_misc import  model_load_dir\n",
    "from extract_targets import get_targets\n",
    "\n",
    "###\n",
    "alpha = 100\n",
    "beta = 10\n",
    "tau = 1e-6\n",
    "layer = 2\n",
    "mixtures = 6\n",
    "temp = 6\n",
    "\n",
    "data_size = 'search'\n",
    "\n",
    "###\n",
    "test_data_full =  Variable(test_data(fetch = \"data\")).cuda()\n",
    "test_labels_full =  Variable(test_data(fetch = \"labels\")).cuda()\n",
    "val_data_full =  Variable(search_validation_data(fetch = \"data\")).cuda()\n",
    "val_labels_full =  Variable(search_validation_data(fetch = \"labels\")).cuda()\n",
    "\n",
    "model_name = \"SWSModel\"\n",
    "model_file = 'mnist_{}_{}_{}'.format(model_name, 100, data_size)\n",
    "model_orig = torch.load(model_load_dir + model_file + '.m').cuda()\n",
    "target_dir = model_file.replace(\"search\", \"full\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 0\n",
    "x_end = 60000\n",
    "if (data_size == \"search\"):\n",
    "    x_start = 40000\n",
    "    x_end = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'> <class 'torch.autograd.variable.Variable'>\n"
     ]
    }
   ],
   "source": [
    "layer = 4\n",
    "if (layer == 1):\n",
    "    layer_model = model_archs.SWSModelConv1().cuda()\n",
    "    input = Variable(train_data(fetch = \"data\")[x_start:x_end]).cuda()\n",
    "    output = get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end]\n",
    "if (layer == 2):\n",
    "    layer_model = model_archs.SWSModelConv2().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"conv1.out\"])[\"conv1.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end]\n",
    "if (layer == 3):\n",
    "    layer_model = model_archs.SWSModelFC1().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"conv2.out\"])[\"conv2.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end]\n",
    "if (layer == 4):\n",
    "    layer_model = model_archs.SWSModelFC2().cuda()\n",
    "    input = nn.ReLU()(get_targets(target_dir, temp, [\"fc1.out\"])[\"fc1.out\"][x_start:x_end])\n",
    "    output = get_targets(target_dir, temp, [\"fc2.out\"])[\"fc2.out\"][x_start:x_end]\n",
    "\n",
    "print (type(input), type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-component Mean: 2500.0 Variance: 1250.0\n",
      "Non-zero component Mean: 10.0 Variance: 1.0\n",
      "Model Name: SWSModelConv2\n",
      "Epoch: 10. Loss: 11.15\n",
      "Original: 98.71% - Retrain: 98.58% - Prune: 13.15%\n",
      "Epoch: 20. Loss: 6.32\n",
      "Original: 98.71% - Retrain: 98.35% - Prune: 9.85%\n",
      "Epoch: 30. Loss: 3.75\n",
      "Original: 98.71% - Retrain: 98.16% - Prune: 9.74%\n",
      "Epoch: 40. Loss: 1.86\n",
      "Original: 98.71% - Retrain: 97.91% - Prune: 9.74%\n",
      "Epoch: 50. Loss: 1.07\n",
      "Original: 98.71% - Retrain: 97.72% - Prune: 9.74%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-02a08783c02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixtures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-61f70b96a632>\u001b[0m in \u001b[0;36mretrain_layer\u001b[0;34m(model_retrain, model_orig, data_loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlayer_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_retrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_retrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mnist_retrain_{}.m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mnist_retrain_{}_gmp.p'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = torch.utils.data.TensorDataset(input.data, output.data)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model, gmp = retrain_layer(layer_model, model_orig, loader, test_data_full, test_labels_full, alpha, beta, tau, mixtures, model_dir + model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layered Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp:100 mean: 0.0032196784442513784, var: 0.8956708445545833, tau: 1.7742852308703055e-08, temp: 2.0, mixtures: 11\n",
      "Original: 98.73% - Retrain: 25.40% - Prune: 32.89% - Sparsity: 0.00%\n",
      "Original: 98.73% - Retrain: 97.61% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 95.68% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 98.14% - Prune: 94.31% - Sparsity: 0.00%\n",
      "test: 9.8, val: 9.91\n",
      "100, 0.0032196784442513784, 0.8956708445545833, 1.7742852308703055e-08, 2, 11, 32.89, 0.0, 10.09, 0.0, 10.09, 100.0, 94.31, 0.0, 9.8, 9.91\n",
      "\n",
      "exp:101 mean: 0.0032196784442513784, var: 0.8956708445545833, tau: 1.7742852308703055e-08, temp: 10.0, mixtures: 8\n",
      "Original: 98.73% - Retrain: 25.38% - Prune: 44.58% - Sparsity: 8.00%\n",
      "Original: 98.73% - Retrain: 97.60% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 95.66% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 80.39% - Prune: 79.85% - Sparsity: 100.00%\n",
      "test: 9.8, val: 9.91\n",
      "101, 0.0032196784442513784, 0.8956708445545833, 1.7742852308703055e-08, 10, 8, 44.58, 8.0, 10.09, 8.0, 10.09, 100.0, 79.85, 100.0, 9.8, 9.91\n",
      "\n",
      "exp:102 mean: 0.0032196784442513784, var: 5764.241761132214, tau: 0.00010673830759454255, temp: 2.0, mixtures: 8\n",
      "Original: 98.73% - Retrain: 66.24% - Prune: 10.09% - Sparsity: 0.00%\n",
      "Original: 98.73% - Retrain: 97.21% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 91.76% - Prune: 90.83% - Sparsity: 98.80%\n",
      "Original: 98.73% - Retrain: 94.55% - Prune: 94.48% - Sparsity: 0.00%\n",
      "test: 9.8, val: 9.91\n",
      "102, 0.0032196784442513784, 5764.241761132214, 0.00010673830759454255, 2, 8, 10.09, 0.0, 10.09, 0.0, 90.83, 98.8, 94.48, 0.0, 9.8, 9.91\n",
      "\n",
      "exp:103 mean: 0.10181517217181825, var: 0.8956708445545833, tau: 0.00010673830759454255, temp: 2.0, mixtures: 8\n",
      "Original: 98.73% - Retrain: 66.27% - Prune: 10.09% - Sparsity: 0.00%\n",
      "Original: 98.73% - Retrain: 97.21% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 91.70% - Prune: 90.79% - Sparsity: 98.60%\n",
      "Original: 98.73% - Retrain: 94.82% - Prune: 94.89% - Sparsity: 0.00%\n",
      "test: 9.8, val: 9.91\n",
      "103, 0.10181517217181825, 0.8956708445545833, 0.00010673830759454255, 2, 8, 10.09, 0.0, 10.09, 0.0, 90.79, 98.6, 94.89, 0.0, 9.8, 9.91\n",
      "\n",
      "exp:104 mean: 0.10181517217181825, var: 5764.241761132214, tau: 1.7742852308703055e-08, temp: 2.0, mixtures: 8\n",
      "Original: 98.73% - Retrain: 25.38% - Prune: 44.63% - Sparsity: 8.00%\n",
      "Original: 98.73% - Retrain: 97.61% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 95.64% - Prune: 10.09% - Sparsity: 100.00%\n",
      "Original: 98.73% - Retrain: 98.14% - Prune: 94.69% - Sparsity: 0.00%\n",
      "test: 9.8, val: 9.91\n",
      "104, 0.10181517217181825, 5764.241761132214, 1.7742852308703055e-08, 2, 8, 44.63, 8.0, 10.09, 8.0, 10.09, 100.0, 94.69, 0.0, 9.8, 9.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../src/')\n",
    "import os\n",
    "import argparse\n",
    "from retrain_model import retrain_model\n",
    "savedir = os.getcwd() + \"/models/\"\n",
    "import copy\n",
    "\n",
    "import pickle\n",
    "from mnist_loader import train_data\n",
    "from utils_sws import sws_prune, compressed_model\n",
    "from utils_model import test_accuracy, layer_accuracy, sws_replace\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mnist_loader import search_train_data, search_retrain_data, search_validation_data, train_data, test_data, batch_size\n",
    "from utils_misc import model_load_dir\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    test_data_full =  Variable(test_data(fetch = \"data\")).cuda()\n",
    "    test_labels_full =  Variable(test_data(fetch = \"labels\")).cuda()\n",
    "    val_data_full =  Variable(search_validation_data(fetch = \"data\")).cuda()\n",
    "    val_labels_full =  Variable(search_validation_data(fetch = \"labels\")).cuda()\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('--start', dest = \"start\", help=\"Start Search\", required=True, type=(int))\n",
    "    #parser.add_argument('--end', dest = \"end\", help=\"End Search\", required=True, type=(int))\n",
    "    #args = parser.parse_args()\n",
    "    #start = int(args.start)\n",
    "    #end = int(args.end)\n",
    "    start = 100\n",
    "    end = 105\n",
    "    \n",
    "    with open(\"../sobol_search.p\", \"rb\") as handle:\n",
    "        params = pickle.load(handle)\n",
    "    for i in range (start,end):\n",
    "        print (\"exp:{} mean: {}, var: {}, tau: {}, temp: {}, mixtures: {}\".format(i, params['mean'][i], params['var'][i], params['tau'][i], float(params['temp'][i]), int(params['mixtures'][i])))\n",
    "        mean = float(params['mean'][i])\n",
    "        var = float(params['var'][i])\n",
    "        beta = mean/var\n",
    "        alpha = mean * beta\n",
    "        \n",
    "        model_name = \"SWSModel\"\n",
    "        model_file = 'mnist_{}_{}_{}'.format(model_name, 100, \"search\")\n",
    "        model_orig = torch.load(model_load_dir + model_file + '.m').cuda()\n",
    "\n",
    "        conv1_exp_name = \"SWSModelConv1_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(alpha, beta, 50, float(params['tau'][i]), int(params['mixtures'][i]), int(params['temp'][i]), 'search')\n",
    "        conv1_model_file = \"./models/mnist_SWSModel_100_searchmnist_retrain_{}\".format(conv1_exp_name)\n",
    "        conv2_exp_name = \"SWSModelConv2_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(alpha, beta, 50, float(params['tau'][i]), int(params['mixtures'][i]), int(params['temp'][i]), 'search')\n",
    "        conv2_model_file = \"./models/mnist_SWSModel_100_searchmnist_retrain_{}\".format(conv2_exp_name)\n",
    "        fc1_exp_name = \"SWSModelFC1_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(alpha, beta, 50, float(params['tau'][i]), int(params['mixtures'][i]), int(params['temp'][i]), 'search')\n",
    "        fc1_model_file = \"./models/mnist_SWSModel_100_searchmnist_retrain_{}\".format(fc1_exp_name)\n",
    "        fc2_exp_name = \"SWSModelFC2_a{}_b{}_r{}_t{}_m{}_kdT{}_{}\".format(alpha, beta, 50, float(params['tau'][i]), int(params['mixtures'][i]), int(params['temp'][i]), 'search')\n",
    "        fc2_model_file = \"./models/mnist_SWSModel_100_searchmnist_retrain_{}\".format(fc2_exp_name)\n",
    "        \n",
    "        conv1_model = torch.load(\"{}.m\".format(conv1_model_file)).cuda()\n",
    "        with open(\"{}_gmp.p\".format(conv1_model_file), \"rb\") as handle:\n",
    "            conv1_gmp = pickle.load(handle)\n",
    "        conv2_model = torch.load(\"{}.m\".format(conv2_model_file)).cuda()\n",
    "        with open(\"{}_gmp.p\".format(conv2_model_file), \"rb\") as handle:\n",
    "            conv2_gmp = pickle.load(handle)\n",
    "        fc1_model = torch.load(\"{}.m\".format(fc1_model_file)).cuda()\n",
    "        with open(\"{}_gmp.p\".format(fc1_model_file), \"rb\") as handle:\n",
    "            fc1_gmp = pickle.load(handle)\n",
    "        fc2_model = torch.load(\"{}.m\".format(fc2_model_file)).cuda()\n",
    "        with open(\"{}_gmp.p\".format(fc2_model_file), \"rb\") as handle:\n",
    "            fc2_gmp = pickle.load(handle)\n",
    "            \n",
    "        conv1_res = layer_accuracy(conv1_model, conv1_gmp, model_orig, val_data_full, val_labels_full)\n",
    "        conv2_res = layer_accuracy(conv2_model, conv2_gmp, model_orig, val_data_full, val_labels_full)\n",
    "        fc1_res = layer_accuracy(fc1_model, fc1_gmp, model_orig, val_data_full, val_labels_full)\n",
    "        fc2_res = layer_accuracy(fc2_model, fc2_gmp, model_orig, val_data_full, val_labels_full)\n",
    "        \n",
    "        pruned_model = sws_replace(model_orig, sws_prune(conv1_model, conv1_gmp), sws_prune(conv2_model, conv2_gmp), sws_prune(fc1_model, fc1_gmp), sws_prune(fc2_model, fc2_gmp))\n",
    "        test_acc = test_accuracy(test_data_full, test_labels_full, pruned_model)[0]\n",
    "        val_acc = test_accuracy(val_data_full, val_labels_full, pruned_model)[0]\n",
    "        print (\"test: {}, val: {}\".format(test_acc, val_acc))\n",
    "        #cm = compressed_model(pruned_model.state_dict(), [conv1_gmp, conv2_gmp, fc1_gmp, fc2_gmp])\n",
    "        #cr = cm.get_cr(6)[0]\n",
    "        #print (\"CR: {}\".format(cr))\n",
    "        #sp = (cm.binned_weights == 0).sum() / float(cm.binned_weights.size) * 100.0\n",
    "        #print (\"SP: {}\".format(sp))\n",
    "        if not os.path.exists(\"results.csv\"):\n",
    "            with open(\"results.csv\", \"w\") as out_csv:\n",
    "                out_csv.write(\"Exp, Mean, Var, Tau, Temp, Mixtures, conv1_val, conv1_sp, conv2_val, conv2_sp, fc1_val, fc1_sp, fc2_val, fc_2sp, Test Acc, Val Acc\\n\")\n",
    "                out_csv.write(\", \".join([str(x) for x in [i, params['mean'][i], params['var'][i], params['tau'][i], int(params['temp'][i]), int(params['mixtures'][i]), \n",
    "                                           conv1_res[1], conv1_res[2], conv2_res[1], conv1_res[2], fc1_res[1], fc1_res[2], fc2_res[1], fc2_res[2], test_acc, val_acc]]) + \"\\n\")\n",
    "        else:\n",
    "            with open(\"results.csv\", \"a\") as out_csv:\n",
    "                out_csv.write(\", \".join([str(x) for x in [i, params['mean'][i], params['var'][i], params['tau'][i], int(params['temp'][i]), int(params['mixtures'][i]), \n",
    "                                           conv1_res[1], conv1_res[2], conv2_res[1], conv1_res[2], fc1_res[1], fc1_res[2], fc2_res[1], fc2_res[2], test_acc, val_acc]]) + \"\\n\")\n",
    "\n",
    "#mnist_retrain_SWSModel_a1.3365233866589001e-06_b0.0004151108285503527_r50_t1.6436915121153314e-07_m6_kdT20_search.m\n",
    "#mnist_retrain_SWSModel_a86791.37374683257_b8.524404751815132_r50_t2.5311641601652367e-05_m9.0_kdT7_search.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.61, 10.09, 100.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
